## 1. MCP(Model Context Protocol)란 무엇인가?

- **정의**
    
    MCP(Model Context Protocol)는 **대형 언어 모델(LLM)**과 외부 데이터 소스·도구 간 **표준화된 연결**을 제공하기 위한 **오픈 프로토콜**이다.
    
    - HTTP가 웹 브라우저와 서버를 연결하듯이, MCP는 AI 모델과 다양한 서비스(파일 시스템, DB, API, 클라우드 서비스 등)를 **단일 프로토콜**로 연결한다.
- **탄생 배경**
    - 기존에는 각 서비스마다 서로 다른 API 통합 방법을 사용해야 했으며, 인증 및 데이터 포맷도 제각각이었다.
    - AI가 실시간 데이터를 활용하거나 특정 작업(코딩, 검색, DB 쿼리 등)을 자동으로 수행하려면 복잡한 연결 과정을 거쳐야 했다.
    - MCP는 이 문제를 해결하기 위해 **‘USB-C와 같은 범용 연결 표준’**을 지향한다.
- **구성 요소**
    - **호스트(Host)**: AI 모델을 통합해 제공하는 애플리케이션(예: Claude Desktop, Cursor, Microsoft Copilot Studio 등).
    - **클라이언트(Client)**: 호스트와 MCP 서버 간의 통신을 **JSON-RPC 2.0** 등으로 중개하는 역할.
    - **서버(Server)**: 각종 **도구(Tools)**, **리소스(Resources)**, **프롬프트(Prompts)** 등을 제공해 AI 모델이 외부 환경과 상호작용 가능하도록 만든 프로그램.
- **핵심 철학**
    1. AI 모델이 필요한 **정보**와 **기능**을 제약 없이 활용할 수 있도록 연결
    2. 표준화된 통신 규칙(프로토콜)을 제공
    3. 인증·보안·사용자 동의 흐름 등을 통합 관리

---

## 2. 왜 MCP가 필요한가?

1. **LLM의 지식·기능 한계 보완**
    - LLM은 학습 시점 이후 발생한 최신 정보나 특정 비즈니스 데이터베이스에 대한 지식이 부족하다.
    - MCP를 통해 **실시간 최신 정보** 또는 **기업 내부 데이터**에 접근할 수 있다.
2. **맞춤형 전문 도구 연결**
    - 예: 엑셀/한글 파일 자동 생성, 데이터베이스 SQL 쿼리, 노션/Slack/이메일/CRM API 등.
    - LLM이 ‘문맥(Context)’을 유지하며 **다양한 도구**를 자동 실행하여 작업한다.
3. **범용 API 표준**
    - 기존에는 각 서비스(API)마다 맞춤형 코드가 필요했으나, MCP로 **일관된 호출 방식**을 제공함으로써 구현·유지보수 비용이 줄어든다.
4. **복잡한 워크플로우 자동화**
    - RAG(Retrieval-Augmented Generation), 코드 자동 완성, 브라우저 디버깅, 검색, 데이터 시각화 등 여러 단계를 AI가 종합적으로 수행 가능.

---

## 3. MCP의 주요 기능 및 특성

1. **JSON-RPC 2.0 기반 통신**
    - 모든 MCP 메시지는 표준 JSON-RPC 스펙을 따른다.
    - 요청과 응답, 에러 포맷이 정형화되어 있어 일관성 높은 연동이 가능하다.
2. **도구(Tools) 제공**
    - **서버**에 정의된 함수(도구)를 AI 모델(호스트)에서 자연어 명령으로 호출할 수 있다.
    - 예: `create_folder(name)`, `execute_sql(query)`, `send_email(to, subject, body)` 등.
3. **리소스(Resources) 제공**
    - 정적/동적 데이터를 제공한다.
    - 예: 파일, DB 테이블, 웹 크롤링 결과, API 결과물 등.
4. **프롬프트(Prompts) 관리**
    - AI 모델이 더 좋은 응답을 하도록, 특정 템플릿이나 가이드를 서버에서 전달할 수 있다.
5. **실시간 양방향 통신**
    - 일부 구현에서는 **Server-Sent Events(SSE)** 등의 기법으로 AI 모델과 서버 간 **실시간** 데이터 교환을 지원한다.
6. **동적 도구 발견**
    - AI 모델은 MCP 서버가 제공하는 도구 목록을 **실행 중에 동적으로 조회**해, 새 도구를 인식하고 활용할 수 있다.
7. **보안 및 승인 흐름**
    - 민감 데이터를 다루거나 시스템 명령을 실행할 경우, **사용자 동의**나 **토큰 인증**을 거치도록 권고된다.
    - “LLM 샘플링 요청에 대한 명시적 사용자 승인 필요” 등 보안·개인정보 보호 지침이 강조된다.

---

## 4. MCP와 기존 방식(API/플러그인/프레임워크) 비교

- **기존 API**
    - 각 서비스마다 URL·파라미터·인증체계가 달라, 통합이 번거롭다.
- **플러그인 방식**
    - 예: ChatGPT Plugins, LangChain Tools 등.
    - 특정 플랫폼/프레임워크 종속적이어서, 다른 AI 모델로 옮기기 어려움.
- **MCP**
    - **모델 독립적인 표준**으로, 호스트(AI 모델이나 앱)를 바꿔도 같은 MCP 서버로 재활용 가능.
    - “USB-C”처럼 한 번 MCP 서버를 만들어두면, AI 모델이 바뀌어도 연결 인터페이스가 유지된다.

---

## 5. MCP 구현 구조

```
rust
복사편집
┌────────────┐       ┌───────────────────┐       ┌────────────┐
│   Host(AI) │ <---> │ Client(JSON-RPC)  │ <---> │   Server   │
└────────────┘       └───────────────────┘       └────────────┘
                           | 도구·리소스·프롬프트 제공 |
                           | 인증/보안 로직 처리        |

```

1. **서버(Server)**
    - MCP 프로토콜에 맞춰 도구·리소스·프롬프트를 등록하고, JSON-RPC 형태의 요청을 처리한다.
    - 예: Python 기반 MCP 서버(`fastMCP`, `mcp.py` 등), Node.js 기반 서버 등.
2. **클라이언트(Client)**
    - 호스트와 서버 간에 오가는 JSON-RPC 메시지를 **중개**.
    - 호스트는 자연어 명령 → ‘도구 호출’ 형태로 클라이언트에 요청 → 클라이언트가 JSON-RPC 요청을 서버에 전달.
3. **호스트(Host)**
    - 사용자 대화 또는 개발 인터페이스를 제공하는 LLM 애플리케이션(Claude, Cursor, ChatGPT, Copilot 등).
    - AI 모델이 서버가 가진 도구를 적절히 골라 문제 해결을 진행.

---

## 6. MCP 사용 사례

1. **데이터베이스(DB)와의 연동**
    - PostgreSQL, Supabase, SQLite 등 DB에 대해 쿼리를 실행해, AI가 실시간 데이터를 분석하거나 업데이트한다.
    - MCP PostgreSQL 서버 예시: 테이블 스키마 확인 + SQL 쿼리 실행 + 결과 반환.
2. **파일 시스템 제어**
    - 엑셀/한글 파일 생성 및 읽기, 폴더 생성, 이미지 분류, 로컬 파일 입출력 자동화 등.
3. **웹 크롤링/검색**
    - FireCrawl, Perplexity, Bing, Google 등의 검색·크롤링 서버와 연동, 최신 뉴스나 특정 웹사이트 데이터를 가져오기.
4. **노션(Notion), Slack, GitHub 등 업무 도구 연동**
    - AI가 명령 한 줄로 노션 페이지 생성, Slack 메시지 전송, GitHub Pull Request 생성 등 자동화.
5. **전자상거래/주문 처리**
    - 제품 API에서 상품 정보를 가져오고, 주문 API로 결제·환불 요청 등을 수행하는 AI 기반 고객지원.
6. **IDE/개발자동화**
    - Cursor 등 에디터와 MCP를 연결, 디버깅·빌드·배포 명령을 자연어로 실행.
7. **이미지 처리**
    - 이미지 파일 열기, 분류, 간단한 편집 등을 AI가 MCP 도구를 통해 수행.

---

## 7. MCP 구현·활용 단계

1. **환경 세팅**
    - Python/Node.js 설치, MCP 서버 예제(오픈소스 레포지토리) 클론, 필수 라이브러리(`pip install`/`npm install`) 설치 등.
2. **서버 설정**
    - `server.py` 또는 `index.js` 등에서 MCP 프로토콜 스펙에 맞게 도구/리소스/프롬프트를 정의.
    - 예) Python에서 `@mcp.tool` 데코레이터로 함수 등록, 리턴 타입·설명(독스트링) 명시.
3. **호스트 연동**
    - 호스트(예: Claude Desktop, Cursor, ChatGPT 등) 설정 파일에서 MCP 서버 주소 또는 로컬 실행 포트 등록.
    - 호스트 재시작 후 도구 목록이 자동 인식되는지 확인.
4. **테스트**
    - AI 대화 창에서 “폴더 만들어 줘”, “이 엑셀에 데이터 입력해 줘” 등 자연어로 테스트.
    - 서버 로그를 확인해 도구 호출이 정상 수행되는지 검사.
5. **보안·인증 설정**
    - Personal Access Token(PAT), OAuth, API Key 등 사용자 승인 흐름을 구현.
    - 시스템 명령, 민감 데이터 접근 시 사용자에게 재확인 절차(“자동 실행 모드 vs 승인 모드”)를 둔다.
6. **운영 및 확장**
    - 여러 MCP 서버를 동시에 등록하여, AI가 다양한 도구를 골라 쓰도록 확장 가능.
    - 기업 환경에서는 VPC(가상 사설망), 데이터 손실 방지(DLP) 등 보안 기능을 MCP 서버 측에 추가.

---

## 8. MCP 보안 및 유의사항

1. **사용자 승인**
    - AI가 시스템 파일을 삭제하거나 민감한 DB를 수정하는 기능을 호출하기 전, **명시적 승인** 과정을 거칠 것을 권장.
2. **서버 신뢰성 검증**
    - 타인이 만든 MCP 서버를 무작정 사용할 경우, 악의적 기능(랜섬, 스파이웨어 등)이 포함될 위험이 있음.
3. **민감 정보 취급**
    - API Key, DB 비밀번호 등 인증 정보는 MCP 서버가 안전하게 저장·관리하도록 설계해야 한다.
4. **LLM의 환각(Hallucination)**
    - AI가 잘못된 함수를 호출하거나 없는 도구를 시도할 수도 있으므로, 예외 처리가 필요하다.
5. **오버헤드**
    - 작은 프로젝트에서는 MCP 서버를 따로 구성하는 것이 번거롭거나 과도한 비용이 될 수 있다.

---

## 9. MCP 도입 시 기대 효과

1. **개발 생산성 향상**
    - 한 번 MCP 서버를 만들어두면, 다양한 AI 모델(혹은 호스트)이 똑같이 재활용 가능하다.
    - 기능 추가·변경 시 서버만 수정하면 되므로, 유지보수가 편리하다.
2. **확장성**
    - 도구(함수)와 리소스가 서버에 집중되어 있어, 프로젝트 규모가 커져도 구조적 혼란이 적다.
3. **실시간 데이터 반영**
    - AI 모델이 매번 사전 학습에 의존하지 않고, 최신 정보를 바로 사용할 수 있어 답변의 정확도 및 시의성이 올라간다.
4. **협업 용이**
    - 회사·팀 단위로 표준화된 MCP 서버를 공유하면, 누구나 동일한 도구 환경을 사용할 수 있다.
5. **에이전트 자동화**
    - AI가 여러 단계를 거쳐 도구들을 연속해서 호출(Sequential Thinking) 가능하므로, 복잡한 업무 프로세스를 자동화할 수 있다.

---

## 10. 결론 및 전망

- **미래 표준화 가능성**
    - 오픈AI, Anthropic 등 주요 AI 기업들이 MCP를 지원·채택하면서 **“AI와 외부 시스템 연결의 사실상 표준”**으로 자리잡을 가능성이 높다.
- **개발자/기업에게 새로운 기회**
    - MCP 서버·클라이언트·툴 마켓플레이스가 성장 중이며, 이를 활용하거나 직접 구현하는 역량이 수요가 높아지고 있다.
- **계속되는 업데이트**
    - SSE 기반 실시간 통신, OAuth 인증, 클라우드 네이티브 운영 등 새로운 기능이 속속 등장하고 있으며, MCP 생태계가 더욱 확장될 전망이다.
- **도입 시점**
    - 아직 초기 시장이지만, 빠르게 MCP 방식으로 인프라를 전환하거나 대비하는 것이 유리하다는 의견이 많다.